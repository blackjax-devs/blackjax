
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>blackjax.optimizers.lbfgs</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/blackjax.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/quickstart.html">
   Quickstart
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  PPL INTEGRATION
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_use_aesara.html">
   Aesara
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_use_numpyro.html">
   Numpyro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_use_oryx.html">
   Oryx
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_use_pymc.html">
   PyMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_use_tfp.html">
   Tensorflow-Probability
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  HOW TO
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_sample_multiple_chains.html">
   Sample with multiple chains?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_custom_gradients.html">
   Use custom gradients?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_other_frameworks.html">
   Use non-JAX log-prob functions?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../examples/howto_metropolis_within_gibbs.html">
   Build a Metropolis-Within-Gibbs sampler?
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  LEARN BY EXAMPLE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://blackjax-devs.github.io/sampling-book">
   The Sampling Book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../autoapi/blackjax/kernels/index.html">
   Sampling algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../autoapi/blackjax/diagnostics/index.html">
   Diagnostics
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../autoapi/blackjax/index.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../autoapi/blackjax/adaptation/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.adaptation
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/adaptation/mass_matrix/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.adaptation.mass_matrix
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/adaptation/meads_adaptation/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.adaptation.meads_adaptation
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/adaptation/pathfinder_adaptation/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.adaptation.pathfinder_adaptation
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/adaptation/step_size/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.adaptation.step_size
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/adaptation/window_adaptation/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.adaptation.window_adaptation
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../autoapi/blackjax/mcmc/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.mcmc
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/diffusions/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.diffusions
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/elliptical_slice/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.elliptical_slice
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/ghmc/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.ghmc
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/hmc/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.hmc
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/integrators/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.integrators
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/irmh/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.irmh
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/mala/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.mala
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/marginal_latent_gaussian/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.marginal_latent_gaussian
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/metrics/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.metrics
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/nuts/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.nuts
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/periodic_orbital/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.periodic_orbital
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/proposal/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.proposal
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/rmh/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.rmh
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/termination/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.termination
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/mcmc/trajectory/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.mcmc.trajectory
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../autoapi/blackjax/sgmcmc/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.sgmcmc
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/sgmcmc/csgld/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.sgmcmc.csgld
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/sgmcmc/diffusions/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.sgmcmc.diffusions
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/sgmcmc/gradients/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.sgmcmc.gradients
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/sgmcmc/sghmc/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.sgmcmc.sghmc
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/sgmcmc/sgld/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.sgmcmc.sgld
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../autoapi/blackjax/smc/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.smc
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/smc/adaptive_tempered/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.smc.adaptive_tempered
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/smc/base/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.smc.base
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/smc/ess/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.smc.ess
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/smc/resampling/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.smc.resampling
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/smc/solver/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.smc.solver
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/smc/tempered/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.smc.tempered
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../autoapi/blackjax/vi/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.vi
      </span>
     </code>
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/vi/meanfield_vi/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.vi.meanfield_vi
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../autoapi/blackjax/vi/pathfinder/index.html">
       <code class="xref py py-mod docutils literal notranslate">
        <span class="pre">
         blackjax.vi.pathfinder
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../autoapi/blackjax/diagnostics/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.diagnostics
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../autoapi/blackjax/kernels/index.html">
     <code class="xref py py-mod docutils literal notranslate">
      <span class="pre">
       blackjax.kernels
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../bib.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/blackjax-devs/blackjax"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for blackjax.optimizers.lbfgs</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2020- The Blackjax Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">NamedTuple</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.random</span>
<span class="kn">import</span> <span class="nn">jaxopt</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">lax</span>
<span class="kn">from</span> <span class="nn">jax.flatten_util</span> <span class="kn">import</span> <span class="n">ravel_pytree</span>
<span class="kn">from</span> <span class="nn">jaxopt._src.lbfgs</span> <span class="kn">import</span> <span class="n">LbfgsState</span>
<span class="kn">from</span> <span class="nn">jaxopt.base</span> <span class="kn">import</span> <span class="n">OptStep</span>

<span class="kn">from</span> <span class="nn">blackjax.types</span> <span class="kn">import</span> <span class="n">Array</span><span class="p">,</span> <span class="n">PyTree</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;LBFGSHistory&quot;</span><span class="p">,</span>
    <span class="s2">&quot;minimize_lbfgs&quot;</span><span class="p">,</span>
    <span class="s2">&quot;lbfgs_inverse_hessian_factors&quot;</span><span class="p">,</span>
    <span class="s2">&quot;lbfgs_inverse_hessian_formula_1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;lbfgs_inverse_hessian_formula_2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;bfgs_sample&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">INIT_STEP_SIZE</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">MIN_STEP_SIZE</span> <span class="o">=</span> <span class="mf">1e-3</span>


<div class="viewcode-block" id="LBFGSHistory"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.LBFGSHistory">[docs]</a><span class="k">class</span> <span class="nc">LBFGSHistory</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Container for the optimization path of a L-BFGS run</span>

<span class="sd">    x</span>
<span class="sd">        History of positions</span>
<span class="sd">    f</span>
<span class="sd">        History of objective values</span>
<span class="sd">    g</span>
<span class="sd">        History of gradient values</span>
<span class="sd">    alpha</span>
<span class="sd">        History of the diagonal elements of the inverse Hessian approximation.</span>
<span class="sd">    update_mask:</span>
<span class="sd">        The indicator of whether the updates of position and gradient are</span>
<span class="sd">        included in the inverse-Hessian approximation or not.</span>
<span class="sd">        (Xi in the paper)</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LBFGSHistory.x"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.LBFGSHistory.x">[docs]</a>    <span class="n">x</span><span class="p">:</span> <span class="n">Array</span></div>
<div class="viewcode-block" id="LBFGSHistory.f"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.LBFGSHistory.f">[docs]</a>    <span class="n">f</span><span class="p">:</span> <span class="n">Array</span></div>
<div class="viewcode-block" id="LBFGSHistory.g"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.LBFGSHistory.g">[docs]</a>    <span class="n">g</span><span class="p">:</span> <span class="n">Array</span></div>
<div class="viewcode-block" id="LBFGSHistory.alpha"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.LBFGSHistory.alpha">[docs]</a>    <span class="n">alpha</span><span class="p">:</span> <span class="n">Array</span></div>
<div class="viewcode-block" id="LBFGSHistory.update_mask"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.LBFGSHistory.update_mask">[docs]</a>    <span class="n">update_mask</span><span class="p">:</span> <span class="n">Array</span></div></div>


<div class="viewcode-block" id="minimize_lbfgs"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.minimize_lbfgs">[docs]</a><span class="k">def</span> <span class="nf">minimize_lbfgs</span><span class="p">(</span>
    <span class="n">fun</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">x0</span><span class="p">:</span> <span class="n">PyTree</span><span class="p">,</span>
    <span class="n">maxiter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">maxcor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">gtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-08</span><span class="p">,</span>
    <span class="n">ftol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">,</span>
    <span class="n">maxls</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">OptStep</span><span class="p">,</span> <span class="n">LBFGSHistory</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Minimize a function using L-BFGS</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fun:</span>
<span class="sd">        function of the form f(x) where x is a pytree and returns a real scalar.</span>
<span class="sd">        The function should be composed of operations with vjp defined.</span>
<span class="sd">    x0:</span>
<span class="sd">        initial guess</span>
<span class="sd">    maxiter:</span>
<span class="sd">        maximum number of iterations</span>
<span class="sd">    maxcor:</span>
<span class="sd">        maximum number of metric corrections (&quot;history size&quot;)</span>
<span class="sd">    ftol:</span>
<span class="sd">        terminates the minimization when `(f_k - f_{k+1}) &lt; ftol`</span>
<span class="sd">    gtol:</span>
<span class="sd">        terminates the minimization when `|g_k|_norm &lt; gtol`</span>
<span class="sd">    maxls:</span>
<span class="sd">        maximum number of line search steps (per iteration)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Optimization results and optimization path</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ravel pytree into flat array.</span>
    <span class="n">x0_raveled</span><span class="p">,</span> <span class="n">unravel_fn</span> <span class="o">=</span> <span class="n">ravel_pytree</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="n">unravel_fn_mapped</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">unravel_fn</span><span class="p">)</span>

    <span class="c1"># Run LBFGS optimizer on flat input.</span>
    <span class="n">last_step_raveled</span><span class="p">,</span> <span class="n">history_raveled</span> <span class="o">=</span> <span class="n">_minimize_lbfgs</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">fun</span><span class="p">(</span><span class="n">unravel_fn</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span>
        <span class="n">x0_raveled</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="p">,</span>
        <span class="n">maxcor</span><span class="p">,</span>
        <span class="n">gtol</span><span class="p">,</span>
        <span class="n">ftol</span><span class="p">,</span>
        <span class="n">maxls</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Unravel final optimization step.</span>
    <span class="n">last_step</span> <span class="o">=</span> <span class="n">OptStep</span><span class="p">(</span>
        <span class="n">params</span><span class="o">=</span><span class="n">unravel_fn</span><span class="p">(</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">params</span><span class="p">),</span>
        <span class="n">state</span><span class="o">=</span><span class="n">LbfgsState</span><span class="p">(</span>
            <span class="n">iter_num</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iter_num</span><span class="p">,</span>
            <span class="n">value</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">grad</span><span class="o">=</span><span class="n">unravel_fn</span><span class="p">(</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">grad</span><span class="p">),</span>
            <span class="n">stepsize</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">stepsize</span><span class="p">,</span>
            <span class="n">error</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">error</span><span class="p">,</span>
            <span class="n">s_history</span><span class="o">=</span><span class="n">unravel_fn_mapped</span><span class="p">(</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">s_history</span><span class="p">),</span>
            <span class="n">y_history</span><span class="o">=</span><span class="n">unravel_fn_mapped</span><span class="p">(</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">y_history</span><span class="p">),</span>
            <span class="n">rho_history</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">rho_history</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">aux</span><span class="o">=</span><span class="n">last_step_raveled</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">aux</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Unravel optimization path history.</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">LBFGSHistory</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">unravel_fn_mapped</span><span class="p">(</span><span class="n">history_raveled</span><span class="o">.</span><span class="n">x</span><span class="p">),</span>
        <span class="n">f</span><span class="o">=</span><span class="n">history_raveled</span><span class="o">.</span><span class="n">f</span><span class="p">,</span>
        <span class="n">g</span><span class="o">=</span><span class="n">unravel_fn_mapped</span><span class="p">(</span><span class="n">history_raveled</span><span class="o">.</span><span class="n">g</span><span class="p">),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="n">unravel_fn_mapped</span><span class="p">(</span><span class="n">history_raveled</span><span class="o">.</span><span class="n">alpha</span><span class="p">),</span>
        <span class="n">update_mask</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">history_raveled</span><span class="o">.</span><span class="n">update_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="n">unravel_fn_mapped</span><span class="p">(</span><span class="n">history_raveled</span><span class="o">.</span><span class="n">update_mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">x0_raveled</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span>
        <span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">last_step</span><span class="p">,</span> <span class="n">history</span></div>


<span class="k">def</span> <span class="nf">_minimize_lbfgs</span><span class="p">(</span>
    <span class="n">fun</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">x0</span><span class="p">:</span> <span class="n">Array</span><span class="p">,</span>
    <span class="n">maxiter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">maxcor</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">gtol</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">ftol</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">maxls</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">OptStep</span><span class="p">,</span> <span class="n">LBFGSHistory</span><span class="p">]:</span>
    <span class="k">def</span> <span class="nf">lbfgs_one_step</span><span class="p">(</span><span class="n">carry</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">state</span><span class="p">),</span> <span class="n">previous_history</span> <span class="o">=</span> <span class="n">carry</span>

        <span class="c1"># this is to help optimization when using log-likelihoods, especially for float 32</span>
        <span class="c1"># it resets stepsize of the line search algorithm back to stating value (INIT_STEP_SIZE) if</span>
        <span class="c1"># it get stuck in very small values</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span>
            <span class="n">stepsize</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">state</span><span class="o">.</span><span class="n">stepsize</span> <span class="o">&lt;</span> <span class="n">MIN_STEP_SIZE</span><span class="p">,</span> <span class="n">INIT_STEP_SIZE</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">stepsize</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># LBFGS use a rolling history, getting the correct index here.</span>
        <span class="n">last</span> <span class="o">=</span> <span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">iter_num</span> <span class="o">%</span> <span class="n">maxcor</span> <span class="o">+</span> <span class="n">maxcor</span><span class="p">)</span> <span class="o">%</span> <span class="n">maxcor</span>
        <span class="n">next_params</span><span class="p">,</span> <span class="n">next_state</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

        <span class="c1"># Recover alpha and update mask</span>
        <span class="n">s_l</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">s_history</span><span class="p">[</span><span class="n">last</span><span class="p">]</span>
        <span class="n">z_l</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">y_history</span><span class="p">[</span><span class="n">last</span><span class="p">]</span>
        <span class="n">alpha_lm1</span> <span class="o">=</span> <span class="n">previous_history</span><span class="o">.</span><span class="n">alpha</span>

        <span class="n">alpha_l</span><span class="p">,</span> <span class="n">mask_l</span> <span class="o">=</span> <span class="n">lbfgs_recover_alpha</span><span class="p">(</span><span class="n">alpha_lm1</span><span class="p">,</span> <span class="n">s_l</span><span class="p">,</span> <span class="n">z_l</span><span class="p">)</span>

        <span class="n">current_grad</span> <span class="o">=</span> <span class="n">previous_history</span><span class="o">.</span><span class="n">g</span> <span class="o">+</span> <span class="n">z_l</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">LBFGSHistory</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">next_params</span><span class="p">,</span>
            <span class="n">f</span><span class="o">=</span><span class="n">next_state</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
            <span class="n">g</span><span class="o">=</span><span class="n">current_grad</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_l</span><span class="p">,</span>
            <span class="n">update_mask</span><span class="o">=</span><span class="n">mask_l</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># check convergence</span>
        <span class="n">f_delta</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">value</span> <span class="o">-</span> <span class="n">next_state</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
            <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">value</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">next_state</span><span class="o">.</span><span class="n">value</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">])</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">not_converged</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_state</span><span class="o">.</span><span class="n">error</span> <span class="o">&gt;</span> <span class="n">gtol</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">f_delta</span> <span class="o">&gt;</span> <span class="n">ftol</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">maxiter</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">OptStep</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">next_params</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">next_state</span><span class="p">),</span> <span class="n">history</span><span class="p">),</span> <span class="n">not_converged</span>

    <span class="k">def</span> <span class="nf">non_op</span><span class="p">(</span><span class="n">carry</span><span class="p">,</span> <span class="n">it</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">carry</span><span class="p">,</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">scan_body</span><span class="p">(</span><span class="n">tup</span><span class="p">,</span> <span class="n">it</span><span class="p">):</span>
        <span class="n">carry</span><span class="p">,</span> <span class="n">not_converged</span> <span class="o">=</span> <span class="n">tup</span>
        <span class="c1"># When cond is met, we start doing no-ops.</span>
        <span class="n">next_tup</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">not_converged</span><span class="p">,</span> <span class="n">lbfgs_one_step</span><span class="p">,</span> <span class="n">non_op</span><span class="p">,</span> <span class="n">carry</span><span class="p">,</span> <span class="n">it</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_tup</span><span class="p">,</span> <span class="n">next_tup</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">solver</span> <span class="o">=</span> <span class="n">jaxopt</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">(</span><span class="n">fun</span><span class="o">=</span><span class="n">fun</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">,</span> <span class="n">maxls</span><span class="o">=</span><span class="n">maxls</span><span class="p">,</span> <span class="n">history_size</span><span class="o">=</span><span class="n">maxcor</span><span class="p">)</span>
    <span class="n">value0</span><span class="p">,</span> <span class="n">grad0</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">fun</span><span class="p">)(</span><span class="n">x0</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

    <span class="n">value0</span><span class="p">,</span> <span class="n">grad0</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">fun</span><span class="p">)(</span><span class="n">x0</span><span class="p">)</span>
    <span class="c1"># LBFGS update overwirte value internally, here is to set the value for checking condition</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">_replace</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">value0</span><span class="p">)</span>
    <span class="n">init_step</span> <span class="o">=</span> <span class="n">OptStep</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">)</span>
    <span class="n">initial_history</span> <span class="o">=</span> <span class="n">LBFGSHistory</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span>
        <span class="n">f</span><span class="o">=</span><span class="n">value0</span><span class="p">,</span>
        <span class="n">g</span><span class="o">=</span><span class="n">grad0</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span>
        <span class="n">update_mask</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="p">((</span><span class="n">last_step</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">_</span><span class="p">),</span> <span class="n">history</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
        <span class="n">scan_body</span><span class="p">,</span> <span class="p">((</span><span class="n">init_step</span><span class="p">,</span> <span class="n">initial_history</span><span class="p">),</span> <span class="kc">True</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">maxiter</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Append initial state to history.</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">initial_history</span><span class="p">,</span>
        <span class="n">history</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">last_step</span><span class="p">,</span> <span class="n">history</span>


<span class="k">def</span> <span class="nf">lbfgs_recover_alpha</span><span class="p">(</span><span class="n">alpha_lm1</span><span class="p">,</span> <span class="n">s_l</span><span class="p">,</span> <span class="n">z_l</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute diagonal elements of the inverse Hessian approximation from optimation path.</span>
<span class="sd">    It implements the inner loop body of Algorithm 3 in :cite:p:`zhang2022pathfinder`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha_lm1</span>
<span class="sd">        The diagonal element of the inverse Hessian approximation of the previous iteration</span>
<span class="sd">    s_l</span>
<span class="sd">        The update of the position (current position - previous position)</span>
<span class="sd">    z_l</span>
<span class="sd">        The update of the gradient (current gradient - previous gradient). Note that in :cite:p:`zhang2022pathfinder`</span>
<span class="sd">        it is defined as the negative of the update of the gradient, but since we are optimizing</span>
<span class="sd">        the negative log prob function taking the update of the gradient is correct here.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    alpha_l</span>
<span class="sd">        The diagonal element of the inverse Hessian approximation of the current iteration</span>
<span class="sd">    mask_l</span>
<span class="sd">        The indicator of whether the update of position and gradient are included in</span>
<span class="sd">        the inverse-Hessian approximation or not.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">compute_next_alpha</span><span class="p">(</span><span class="n">s_l</span><span class="p">,</span> <span class="n">z_l</span><span class="p">,</span> <span class="n">alpha_lm1</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">z_l</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">alpha_lm1</span><span class="p">)</span> <span class="o">@</span> <span class="n">z_l</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">z_l</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">s_l</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">s_l</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">alpha_lm1</span><span class="p">)</span> <span class="o">@</span> <span class="n">s_l</span>
        <span class="n">inv_alpha_l</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">alpha_lm1</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">z_l</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">b</span>
            <span class="o">-</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">s_l</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">c</span> <span class="o">*</span> <span class="n">alpha_lm1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">inv_alpha_l</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">s_l</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">z_l</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">epsilon</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">z_l</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">alpha_l</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
        <span class="n">pred</span><span class="p">,</span> <span class="n">compute_next_alpha</span><span class="p">,</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">alpha_lm1</span><span class="p">,</span> <span class="n">s_l</span><span class="p">,</span> <span class="n">z_l</span><span class="p">,</span> <span class="n">alpha_lm1</span>
    <span class="p">)</span>
    <span class="n">mask_l</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">pred</span><span class="p">,</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">alpha_lm1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">),</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">alpha_lm1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">alpha_l</span><span class="p">,</span> <span class="n">mask_l</span>


<div class="viewcode-block" id="lbfgs_inverse_hessian_factors"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.lbfgs_inverse_hessian_factors">[docs]</a><span class="k">def</span> <span class="nf">lbfgs_inverse_hessian_factors</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates factors for inverse hessian factored representation.</span>
<span class="sd">    It implements formula II.2 of:</span>

<span class="sd">    Pathfinder: Parallel quasi-newton variational inference, Lu Zhang et al., arXiv:2108.03782</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">param_dims</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">StZ</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Z</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">StZ</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">param_dims</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>

    <span class="n">eta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">StZ</span><span class="p">)</span>

    <span class="n">beta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span><span class="p">,</span> <span class="n">S</span><span class="p">])</span>

    <span class="n">minvR</span> <span class="o">=</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
    <span class="n">alphaZ</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span> <span class="o">@</span> <span class="n">Z</span>
    <span class="n">block_dd</span> <span class="o">=</span> <span class="n">minvR</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">alphaZ</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">alphaZ</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">eta</span><span class="p">))</span> <span class="o">@</span> <span class="n">minvR</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">block</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">param_dims</span><span class="p">,</span> <span class="n">param_dims</span><span class="p">)),</span> <span class="n">minvR</span><span class="p">],</span> <span class="p">[</span><span class="n">minvR</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">block_dd</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span></div>


<div class="viewcode-block" id="lbfgs_inverse_hessian_formula_1"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.lbfgs_inverse_hessian_formula_1">[docs]</a><span class="k">def</span> <span class="nf">lbfgs_inverse_hessian_formula_1</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates inverse hessian from factors as in formula II.1 of:</span>

<span class="sd">    Pathfinder: Parallel quasi-newton variational inference, Lu Zhang et al., arXiv:2108.03782</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">@</span> <span class="n">gamma</span> <span class="o">@</span> <span class="n">beta</span><span class="o">.</span><span class="n">T</span></div>


<div class="viewcode-block" id="lbfgs_inverse_hessian_formula_2"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.lbfgs_inverse_hessian_formula_2">[docs]</a><span class="k">def</span> <span class="nf">lbfgs_inverse_hessian_formula_2</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates inverse hessian from factors as in formula II.3 of:</span>

<span class="sd">    Pathfinder: Parallel quasi-newton variational inference, Lu Zhang et al., arXiv:2108.03782</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">param_dims</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dsqrt_alpha</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
    <span class="n">idsqrt_alpha</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">dsqrt_alpha</span>
        <span class="o">@</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">param_dims</span><span class="p">)</span> <span class="o">+</span> <span class="n">idsqrt_alpha</span> <span class="o">@</span> <span class="n">beta</span> <span class="o">@</span> <span class="n">gamma</span> <span class="o">@</span> <span class="n">beta</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">idsqrt_alpha</span><span class="p">)</span>
        <span class="o">@</span> <span class="n">dsqrt_alpha</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="bfgs_sample"><a class="viewcode-back" href="../../../autoapi/blackjax/optimizers/lbfgs/index.html#blackjax.optimizers.lbfgs.bfgs_sample">[docs]</a><span class="k">def</span> <span class="nf">bfgs_sample</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">grad_position</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws approximate samples of target distribution.</span>
<span class="sd">    It implements Algorithm 4 in:</span>

<span class="sd">    Pathfinder: Parallel quasi-newton variational inference, Lu Zhang et al., arXiv:2108.03782</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span>

    <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">))</span> <span class="o">@</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">param_dims</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Id</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">R</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">Id</span> <span class="o">+</span> <span class="n">R</span> <span class="o">@</span> <span class="n">gamma</span> <span class="o">@</span> <span class="n">R</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="n">logdet</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">L</span><span class="p">))</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">position</span>
        <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">@</span> <span class="n">grad_position</span>
        <span class="o">+</span> <span class="n">beta</span> <span class="o">@</span> <span class="n">gamma</span> <span class="o">@</span> <span class="n">beta</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">grad_position</span>
    <span class="p">)</span>

    <span class="n">u</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">num_samples</span> <span class="o">+</span> <span class="p">(</span><span class="n">param_dims</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span> <span class="o">@</span> <span class="p">(</span><span class="n">Q</span> <span class="o">@</span> <span class="p">(</span><span class="n">L</span> <span class="o">-</span> <span class="n">Id</span><span class="p">)</span> <span class="o">@</span> <span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">u</span><span class="p">)</span> <span class="o">+</span> <span class="n">u</span><span class="p">)</span>

    <span class="n">logdensity</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">logdet</span>
        <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;...ji,...ji-&gt;...&quot;</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
        <span class="o">+</span> <span class="n">param_dims</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">phi</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">logdensity</span></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Blackjax developers<br/>
  
      &copy; Copyright 2023, The Blackjax developers.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>