
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Change of Variable in HMC &#8212; Blackjax</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pathfinder" href="Pathfinder.html" />
    <link rel="prev" title="MNIST Digit Recognition With a 3-Layer Perceptron" href="SGMCMC.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/blackjax.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Blackjax</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Blackjax by example
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../examples.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Introduction.html">
     A Quick Introduction to Blackjax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="MultipleChains.html">
     Sampling Multiple Chains
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="LogisticRegression.html">
     Bayesian Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="LogisticRegressionWithLatentGaussianSampler.html">
     Bayesian Logistic Regression With Latent Gaussian Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="TemperedSMC.html">
     Use Tempered SMC to Improve Exploration of MCMC Methods.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalBNN.html">
     Hierarchical Bayesian Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="PeriodicOrbitalMCMC.html">
     Periodic Orbital MCMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GP_EllipticalSliceSampler.html">
     Gaussian Regression with the Elliptical Slice Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SGMCMC.html">
     MNIST Digit Recognition With a 3-Layer Perceptron
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Change of Variable in HMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Pathfinder.html">
     Pathfinder
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling.html">
   Sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../adaptation.html">
   Adaptation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../diagnostics.html">
   Diagnostics
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/blackjax-devs/blackjax"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#posterior-sampling">
   Posterior Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arviz-plots">
   Arviz Plots
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#change-of-variable">
   Change of Variable
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Change of Variable in HMC</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#posterior-sampling">
   Posterior Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arviz-plots">
   Arviz Plots
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#change-of-variable">
   Change of Variable
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="change-of-variable-in-hmc">
<h1>Change of Variable in HMC<a class="headerlink" href="#change-of-variable-in-hmc" title="Permalink to this headline">#</a></h1>
<p><strong>Rat tumor problem:</strong> We have J certain kinds of rat tumor diseases. For each kind of tumor, we test <span class="math notranslate nohighlight">\(N_{j}\)</span> people/animals and among those <span class="math notranslate nohighlight">\(y_{j}\)</span> tested positive. Here we assume that <span class="math notranslate nohighlight">\(y_{j}\)</span> is distrubuted with <strong>Binom</strong>(<span class="math notranslate nohighlight">\(N_{i}\)</span>, <span class="math notranslate nohighlight">\(\theta_{i}\)</span>). Our objective is to approximate <span class="math notranslate nohighlight">\(\theta_{j}\)</span> for each type of tumor.</p>
<p>In particular we use following binomial hierarchical model where <span class="math notranslate nohighlight">\(y_{j}\)</span> and <span class="math notranslate nohighlight">\(N_{j}\)</span> are observed variables.</p>
<table>
<tr>
</tr>
<tr>
<td>
<p><img alt="image.png" src="https://github.com/karm-patel/karm-patel.github.io/blob/master/images/binomial_hierarchichal.png?raw=True" /></p>
</td>
<td>
<p>\begin{align}
y_{j} &amp;\sim \text{Binom}(N_{j}, \theta_{j}) \label{eq:1} \
\theta_{j} &amp;\sim \text{Beta}(a, b) \label{eq:2} \
p(a, b) &amp;\propto (a+b)^{-5/2}
\end{align}</p>
</td>
</tr>
</table><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">blackjax</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="o">%</span><span class="k">pip</span> install -qq jaxopt blackjax
    <span class="kn">import</span> <span class="nn">blackjax</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">tensorflow_probability.substrates.jax</span> <span class="k">as</span> <span class="nn">tfp</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="o">%</span><span class="k">pip</span> install -qq tensorflow_probability
    <span class="kn">import</span> <span class="nn">tensorflow_probability.substrates.jax</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="n">tfd</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;xtick&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>  <span class="c1"># fontsize of the xtick labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;ytick&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>  <span class="c1"># fontsize of the tyick labels</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-12 12:34:43.993874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-09-12 12:34:44.030750: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-09-12 12:34:45.025685: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer.so.7&#39;; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-09-12 12:34:45.025823: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer_plugin.so.7&#39;; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-09-12 12:34:45.025835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
</pre></div>
</div>
</div>
</div>
<section id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># index of array is type of tumor and value shows number of total people tested.</span>
<span class="n">group_size</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">18</span><span class="p">,</span>
        <span class="mi">18</span><span class="p">,</span>
        <span class="mi">17</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">18</span><span class="p">,</span>
        <span class="mi">18</span><span class="p">,</span>
        <span class="mi">25</span><span class="p">,</span>
        <span class="mi">24</span><span class="p">,</span>
        <span class="mi">23</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">10</span><span class="p">,</span>
        <span class="mi">49</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">46</span><span class="p">,</span>
        <span class="mi">27</span><span class="p">,</span>
        <span class="mi">17</span><span class="p">,</span>
        <span class="mi">49</span><span class="p">,</span>
        <span class="mi">47</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">13</span><span class="p">,</span>
        <span class="mi">48</span><span class="p">,</span>
        <span class="mi">50</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">48</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">22</span><span class="p">,</span>
        <span class="mi">46</span><span class="p">,</span>
        <span class="mi">49</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">23</span><span class="p">,</span>
        <span class="mi">19</span><span class="p">,</span>
        <span class="mi">22</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">20</span><span class="p">,</span>
        <span class="mi">52</span><span class="p">,</span>
        <span class="mi">46</span><span class="p">,</span>
        <span class="mi">47</span><span class="p">,</span>
        <span class="mi">24</span><span class="p">,</span>
        <span class="mi">14</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># index of array is type of tumor and value shows number of positve people.</span>
<span class="n">n_of_positives</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">7</span><span class="p">,</span>
        <span class="mi">7</span><span class="p">,</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="mi">9</span><span class="p">,</span>
        <span class="mi">10</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">10</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">11</span><span class="p">,</span>
        <span class="mi">12</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">6</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">6</span><span class="p">,</span>
        <span class="mi">6</span><span class="p">,</span>
        <span class="mi">6</span><span class="p">,</span>
        <span class="mi">6</span><span class="p">,</span>
        <span class="mi">16</span><span class="p">,</span>
        <span class="mi">15</span><span class="p">,</span>
        <span class="mi">15</span><span class="p">,</span>
        <span class="mi">9</span><span class="p">,</span>
        <span class="mi">4</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># number of different kind of rat tumors</span>
<span class="n">n_rat_tumors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">group_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_rat_tumors</span><span class="p">),</span> <span class="n">n_of_positives</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;No. of positives for each tumor type&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;tumor type&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/873477c4170c983c4aeca458cd7876b37971cc328c1f63c9326539cdd6b142ad.png" src="../_images/873477c4170c983c4aeca458cd7876b37971cc328c1f63c9326539cdd6b142ad.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_rat_tumors</span><span class="p">),</span> <span class="n">group_size</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Group size for each tumor type&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;tumor type&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/61eb2cbd961b5568894f4a74c2bb662af95201cf0b992b25c404193a46988466.png" src="../_images/61eb2cbd961b5568894f4a74c2bb662af95201cf0b992b25c404193a46988466.png" />
</div>
</div>
</section>
<section id="posterior-sampling">
<h2>Posterior Sampling<a class="headerlink" href="#posterior-sampling" title="Permalink to this headline">#</a></h2>
<p>Now we use Blackjax’s NUTS algorithm to get posterior samples of <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span>, and <span class="math notranslate nohighlight">\(\theta\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">joint_logprob</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">thetas</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;thetas&quot;</span><span class="p">]</span>

    <span class="c1"># improper prior for a,b</span>
    <span class="n">logprob_ab</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5</span><span class="p">))</span>

    <span class="c1"># logprob prior of theta</span>
    <span class="n">logprob_thetas</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># loglikelihood of y</span>
    <span class="n">logprob_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">probs</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">y</span><span class="p">))(</span>
            <span class="n">n_of_positives</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">thetas</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">logprob_ab</span> <span class="o">+</span> <span class="n">logprob_thetas</span> <span class="o">+</span> <span class="n">logprob_y</span>
</pre></div>
</div>
</div>
</div>
<p>We take initial parameters from uniform distribution</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_params</span> <span class="o">=</span> <span class="n">n_rat_tumors</span> <span class="o">+</span> <span class="mi">2</span>


<span class="k">def</span> <span class="nf">init_param_fn</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    initialize a, b &amp; thetas</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">key1</span><span class="p">,</span> <span class="n">key2</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">key1</span><span class="p">),</span>
        <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">key2</span><span class="p">),</span>
        <span class="s2">&quot;thetas&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_rat_tumors</span><span class="p">,</span> <span class="n">seed</span><span class="p">),</span>
    <span class="p">}</span>


<span class="n">init_param</span> <span class="o">=</span> <span class="n">init_param_fn</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
<span class="n">joint_logprob</span><span class="p">(</span><span class="n">init_param</span><span class="p">)</span>  <span class="c1"># sanity check</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DeviceArray(-1241.5929, dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>Now we use blackjax’s window adaption algorithm to get NUTS kernel and initial states. Window adaption algorithm will automatically configure <code class="docutils literal notranslate"><span class="pre">inverse_mass_matrix</span></code> and <code class="docutils literal notranslate"><span class="pre">step</span> <span class="pre">size</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">warmup</span> <span class="o">=</span> <span class="n">blackjax</span><span class="o">.</span><span class="n">window_adaptation</span><span class="p">(</span><span class="n">blackjax</span><span class="o">.</span><span class="n">nuts</span><span class="p">,</span> <span class="n">joint_logprob</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># we use 4 chains for sampling</span>
<span class="n">n_chains</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">n_chains</span><span class="p">)</span>
<span class="n">init_params</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">init_param_fn</span><span class="p">)(</span><span class="n">keys</span><span class="p">)</span>

<span class="n">initial_states</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">seed</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">warmup</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">param</span><span class="p">)[</span><span class="mi">0</span><span class="p">])(</span>
    <span class="n">keys</span><span class="p">,</span> <span class="n">init_params</span>
<span class="p">)</span>

<span class="c1"># can not vectorize kernel, since it is not jax.numpy array</span>
<span class="n">_</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">warmup</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">init_param_fn</span><span class="p">(</span><span class="n">rng_key</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 26.6 s, sys: 141 ms, total: 26.8 s
Wall time: 26.7 s
</pre></div>
</div>
</div>
</div>
<p>Now we write inference loop for multiple chains</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inference_loop_multiple_chains</span><span class="p">(</span>
    <span class="n">rng_key</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">initial_states</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_chains</span>
<span class="p">):</span>
    <span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
    <span class="k">def</span> <span class="nf">one_step</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">rng_key</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">)</span>
        <span class="n">states</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">kernel</span><span class="p">)(</span><span class="n">keys</span><span class="p">,</span> <span class="n">states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">infos</span><span class="p">)</span>

    <span class="n">keys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">infos</span><span class="p">)</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">one_step</span><span class="p">,</span> <span class="n">initial_states</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">infos</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">states</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">inference_loop_multiple_chains</span><span class="p">(</span>
    <span class="n">rng_key</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">initial_states</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_chains</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 11 s, sys: 76.2 ms, total: 11.1 s
Wall time: 11.1 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;thetas&#39;])
</pre></div>
</div>
</div>
</div>
</section>
<section id="arviz-plots">
<h2>Arviz Plots<a class="headerlink" href="#arviz-plots" title="Permalink to this headline">#</a></h2>
<p>We have all our posterior samples stored in <code class="docutils literal notranslate"><span class="pre">states.position</span></code> dictionary and <code class="docutils literal notranslate"><span class="pre">infos</span></code> store additional information like acceptance probability, divergence, etc. Now, we can use certain diagnostics to judge if our MCMC samples are converged on stationary distribution. Some of widely diagnostics are trace plots, potential scale reduction factor (R hat), divergences, etc. <code class="docutils literal notranslate"><span class="pre">Arviz</span></code> library provides quicker ways to anaylze these diagnostics. We can use <code class="docutils literal notranslate"><span class="pre">arviz.summary()</span></code> and <code class="docutils literal notranslate"><span class="pre">arviz_plot_trace()</span></code>, but these functions take specific format (arviz’s trace) as a input. So now first we will convert <code class="docutils literal notranslate"><span class="pre">states</span></code> and <code class="docutils literal notranslate"><span class="pre">infos</span></code> into <code class="docutils literal notranslate"><span class="pre">trace</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">arviz_trace_from_states</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">info</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">DeviceArray</span>
    <span class="p">):</span>  <span class="c1"># if states.position is array of samples</span>
        <span class="n">ndims</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ndims</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;samples&quot;</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)}</span>
            <span class="n">divergence</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">info</span><span class="o">.</span><span class="n">is_divergent</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">divergence</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">is_divergent</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>

    <span class="k">else</span><span class="p">:</span>  <span class="c1"># if states.position is dict</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">ndims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="n">param</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ndims</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="n">param</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span>
                    <span class="p">:,</span> <span class="n">burn_in</span><span class="p">:</span>
                <span class="p">]</span>  <span class="c1"># swap n_samples and n_chains</span>
                <span class="n">divergence</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">info</span><span class="o">.</span><span class="n">is_divergent</span><span class="p">[</span><span class="n">burn_in</span><span class="p">:],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">ndims</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">divergence</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">is_divergent</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="n">param</span><span class="p">]</span>

    <span class="n">trace_posterior</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">convert_to_inference_data</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">trace_sample_stats</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">convert_to_inference_data</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;diverging&quot;</span><span class="p">:</span> <span class="n">divergence</span><span class="p">},</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;sample_stats&quot;</span>
    <span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">trace_posterior</span><span class="p">,</span> <span class="n">trace_sample_stats</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">trace</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make arviz trace from states</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">arviz_trace_from_states</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">infos</span><span class="p">)</span>
<span class="n">summ_df</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
<span class="n">summ_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>0.669</td>
      <td>0.061</td>
      <td>0.550</td>
      <td>0.733</td>
      <td>0.029</td>
      <td>0.022</td>
      <td>6.0</td>
      <td>26.0</td>
      <td>1.70</td>
    </tr>
    <tr>
      <th>b</th>
      <td>2.148</td>
      <td>0.429</td>
      <td>1.756</td>
      <td>2.935</td>
      <td>0.212</td>
      <td>0.162</td>
      <td>5.0</td>
      <td>19.0</td>
      <td>2.55</td>
    </tr>
    <tr>
      <th>thetas[0]</th>
      <td>0.031</td>
      <td>0.022</td>
      <td>0.000</td>
      <td>0.065</td>
      <td>0.010</td>
      <td>0.008</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>2.34</td>
    </tr>
    <tr>
      <th>thetas[1]</th>
      <td>0.027</td>
      <td>0.034</td>
      <td>0.000</td>
      <td>0.113</td>
      <td>0.015</td>
      <td>0.012</td>
      <td>7.0</td>
      <td>14.0</td>
      <td>1.61</td>
    </tr>
    <tr>
      <th>thetas[2]</th>
      <td>0.151</td>
      <td>0.102</td>
      <td>0.035</td>
      <td>0.314</td>
      <td>0.051</td>
      <td>0.039</td>
      <td>5.0</td>
      <td>27.0</td>
      <td>2.95</td>
    </tr>
    <tr>
      <th>thetas[3]</th>
      <td>0.025</td>
      <td>0.021</td>
      <td>0.000</td>
      <td>0.064</td>
      <td>0.008</td>
      <td>0.006</td>
      <td>6.0</td>
      <td>24.0</td>
      <td>1.79</td>
    </tr>
    <tr>
      <th>thetas[4]</th>
      <td>0.020</td>
      <td>0.010</td>
      <td>0.000</td>
      <td>0.037</td>
      <td>0.004</td>
      <td>0.003</td>
      <td>10.0</td>
      <td>30.0</td>
      <td>1.32</td>
    </tr>
    <tr>
      <th>thetas[5]</th>
      <td>0.144</td>
      <td>0.162</td>
      <td>0.000</td>
      <td>0.435</td>
      <td>0.081</td>
      <td>0.062</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>2.69</td>
    </tr>
    <tr>
      <th>thetas[6]</th>
      <td>0.019</td>
      <td>0.019</td>
      <td>0.000</td>
      <td>0.058</td>
      <td>0.009</td>
      <td>0.007</td>
      <td>6.0</td>
      <td>14.0</td>
      <td>2.07</td>
    </tr>
    <tr>
      <th>thetas[7]</th>
      <td>0.094</td>
      <td>0.090</td>
      <td>0.000</td>
      <td>0.271</td>
      <td>0.044</td>
      <td>0.034</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>3.01</td>
    </tr>
    <tr>
      <th>thetas[8]</th>
      <td>0.051</td>
      <td>0.063</td>
      <td>0.001</td>
      <td>0.164</td>
      <td>0.031</td>
      <td>0.024</td>
      <td>6.0</td>
      <td>14.0</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>thetas[9]</th>
      <td>0.097</td>
      <td>0.100</td>
      <td>0.000</td>
      <td>0.264</td>
      <td>0.049</td>
      <td>0.038</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>2.86</td>
    </tr>
    <tr>
      <th>thetas[10]</th>
      <td>0.017</td>
      <td>0.015</td>
      <td>0.000</td>
      <td>0.041</td>
      <td>0.005</td>
      <td>0.004</td>
      <td>8.0</td>
      <td>23.0</td>
      <td>1.44</td>
    </tr>
    <tr>
      <th>thetas[11]</th>
      <td>0.013</td>
      <td>0.015</td>
      <td>0.000</td>
      <td>0.041</td>
      <td>0.005</td>
      <td>0.004</td>
      <td>10.0</td>
      <td>21.0</td>
      <td>1.32</td>
    </tr>
    <tr>
      <th>thetas[12]</th>
      <td>0.021</td>
      <td>0.018</td>
      <td>0.000</td>
      <td>0.061</td>
      <td>0.008</td>
      <td>0.006</td>
      <td>6.0</td>
      <td>12.0</td>
      <td>1.91</td>
    </tr>
    <tr>
      <th>thetas[13]</th>
      <td>0.087</td>
      <td>0.073</td>
      <td>0.000</td>
      <td>0.196</td>
      <td>0.035</td>
      <td>0.027</td>
      <td>5.0</td>
      <td>16.0</td>
      <td>2.30</td>
    </tr>
    <tr>
      <th>thetas[14]</th>
      <td>0.053</td>
      <td>0.031</td>
      <td>0.002</td>
      <td>0.093</td>
      <td>0.015</td>
      <td>0.011</td>
      <td>5.0</td>
      <td>15.0</td>
      <td>2.18</td>
    </tr>
    <tr>
      <th>thetas[15]</th>
      <td>0.071</td>
      <td>0.052</td>
      <td>0.006</td>
      <td>0.144</td>
      <td>0.024</td>
      <td>0.018</td>
      <td>5.0</td>
      <td>19.0</td>
      <td>2.54</td>
    </tr>
    <tr>
      <th>thetas[16]</th>
      <td>0.086</td>
      <td>0.087</td>
      <td>0.005</td>
      <td>0.243</td>
      <td>0.042</td>
      <td>0.033</td>
      <td>6.0</td>
      <td>18.0</td>
      <td>2.02</td>
    </tr>
    <tr>
      <th>thetas[17]</th>
      <td>0.071</td>
      <td>0.036</td>
      <td>0.001</td>
      <td>0.124</td>
      <td>0.016</td>
      <td>0.012</td>
      <td>5.0</td>
      <td>19.0</td>
      <td>2.01</td>
    </tr>
    <tr>
      <th>thetas[18]</th>
      <td>0.183</td>
      <td>0.121</td>
      <td>0.031</td>
      <td>0.377</td>
      <td>0.060</td>
      <td>0.046</td>
      <td>5.0</td>
      <td>32.0</td>
      <td>2.98</td>
    </tr>
    <tr>
      <th>thetas[19]</th>
      <td>0.094</td>
      <td>0.067</td>
      <td>0.012</td>
      <td>0.210</td>
      <td>0.032</td>
      <td>0.025</td>
      <td>5.0</td>
      <td>17.0</td>
      <td>2.38</td>
    </tr>
    <tr>
      <th>thetas[20]</th>
      <td>0.066</td>
      <td>0.036</td>
      <td>0.020</td>
      <td>0.117</td>
      <td>0.018</td>
      <td>0.014</td>
      <td>5.0</td>
      <td>23.0</td>
      <td>2.22</td>
    </tr>
    <tr>
      <th>thetas[21]</th>
      <td>0.104</td>
      <td>0.079</td>
      <td>0.009</td>
      <td>0.252</td>
      <td>0.039</td>
      <td>0.030</td>
      <td>5.0</td>
      <td>13.0</td>
      <td>2.64</td>
    </tr>
    <tr>
      <th>thetas[22]</th>
      <td>0.128</td>
      <td>0.062</td>
      <td>0.025</td>
      <td>0.232</td>
      <td>0.028</td>
      <td>0.022</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>2.54</td>
    </tr>
    <tr>
      <th>thetas[23]</th>
      <td>0.205</td>
      <td>0.121</td>
      <td>0.066</td>
      <td>0.412</td>
      <td>0.060</td>
      <td>0.046</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>2.98</td>
    </tr>
    <tr>
      <th>thetas[24]</th>
      <td>0.158</td>
      <td>0.053</td>
      <td>0.110</td>
      <td>0.284</td>
      <td>0.026</td>
      <td>0.020</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>1.98</td>
    </tr>
    <tr>
      <th>thetas[25]</th>
      <td>0.164</td>
      <td>0.152</td>
      <td>0.030</td>
      <td>0.418</td>
      <td>0.076</td>
      <td>0.058</td>
      <td>5.0</td>
      <td>15.0</td>
      <td>3.13</td>
    </tr>
    <tr>
      <th>thetas[26]</th>
      <td>0.172</td>
      <td>0.044</td>
      <td>0.111</td>
      <td>0.251</td>
      <td>0.022</td>
      <td>0.017</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>4.00</td>
    </tr>
    <tr>
      <th>thetas[27]</th>
      <td>0.080</td>
      <td>0.027</td>
      <td>0.024</td>
      <td>0.114</td>
      <td>0.012</td>
      <td>0.009</td>
      <td>5.0</td>
      <td>23.0</td>
      <td>2.25</td>
    </tr>
    <tr>
      <th>thetas[28]</th>
      <td>0.126</td>
      <td>0.053</td>
      <td>0.033</td>
      <td>0.196</td>
      <td>0.025</td>
      <td>0.019</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>2.24</td>
    </tr>
    <tr>
      <th>thetas[29]</th>
      <td>0.165</td>
      <td>0.066</td>
      <td>0.070</td>
      <td>0.281</td>
      <td>0.032</td>
      <td>0.025</td>
      <td>5.0</td>
      <td>22.0</td>
      <td>2.71</td>
    </tr>
    <tr>
      <th>thetas[30]</th>
      <td>0.099</td>
      <td>0.048</td>
      <td>0.033</td>
      <td>0.166</td>
      <td>0.022</td>
      <td>0.017</td>
      <td>5.0</td>
      <td>27.0</td>
      <td>2.17</td>
    </tr>
    <tr>
      <th>thetas[31]</th>
      <td>0.146</td>
      <td>0.098</td>
      <td>0.016</td>
      <td>0.348</td>
      <td>0.047</td>
      <td>0.036</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>3.10</td>
    </tr>
    <tr>
      <th>thetas[32]</th>
      <td>0.128</td>
      <td>0.050</td>
      <td>0.027</td>
      <td>0.214</td>
      <td>0.021</td>
      <td>0.016</td>
      <td>5.0</td>
      <td>21.0</td>
      <td>2.05</td>
    </tr>
    <tr>
      <th>thetas[33]</th>
      <td>0.156</td>
      <td>0.087</td>
      <td>0.023</td>
      <td>0.260</td>
      <td>0.043</td>
      <td>0.033</td>
      <td>4.0</td>
      <td>13.0</td>
      <td>3.25</td>
    </tr>
    <tr>
      <th>thetas[34]</th>
      <td>0.117</td>
      <td>0.035</td>
      <td>0.054</td>
      <td>0.181</td>
      <td>0.015</td>
      <td>0.012</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>2.01</td>
    </tr>
    <tr>
      <th>thetas[35]</th>
      <td>0.124</td>
      <td>0.057</td>
      <td>0.052</td>
      <td>0.238</td>
      <td>0.027</td>
      <td>0.020</td>
      <td>5.0</td>
      <td>25.0</td>
      <td>2.14</td>
    </tr>
    <tr>
      <th>thetas[36]</th>
      <td>0.123</td>
      <td>0.063</td>
      <td>0.058</td>
      <td>0.235</td>
      <td>0.031</td>
      <td>0.024</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>2.58</td>
    </tr>
    <tr>
      <th>thetas[37]</th>
      <td>0.142</td>
      <td>0.040</td>
      <td>0.073</td>
      <td>0.200</td>
      <td>0.016</td>
      <td>0.012</td>
      <td>7.0</td>
      <td>42.0</td>
      <td>1.67</td>
    </tr>
    <tr>
      <th>thetas[38]</th>
      <td>0.131</td>
      <td>0.030</td>
      <td>0.087</td>
      <td>0.174</td>
      <td>0.014</td>
      <td>0.011</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>2.31</td>
    </tr>
    <tr>
      <th>thetas[39]</th>
      <td>0.212</td>
      <td>0.085</td>
      <td>0.072</td>
      <td>0.317</td>
      <td>0.039</td>
      <td>0.029</td>
      <td>6.0</td>
      <td>13.0</td>
      <td>1.93</td>
    </tr>
    <tr>
      <th>thetas[40]</th>
      <td>0.165</td>
      <td>0.070</td>
      <td>0.077</td>
      <td>0.279</td>
      <td>0.033</td>
      <td>0.025</td>
      <td>5.0</td>
      <td>25.0</td>
      <td>2.15</td>
    </tr>
    <tr>
      <th>thetas[41]</th>
      <td>0.181</td>
      <td>0.071</td>
      <td>0.067</td>
      <td>0.259</td>
      <td>0.035</td>
      <td>0.027</td>
      <td>5.0</td>
      <td>23.0</td>
      <td>3.05</td>
    </tr>
    <tr>
      <th>thetas[42]</th>
      <td>0.244</td>
      <td>0.052</td>
      <td>0.140</td>
      <td>0.328</td>
      <td>0.025</td>
      <td>0.019</td>
      <td>5.0</td>
      <td>16.0</td>
      <td>2.79</td>
    </tr>
    <tr>
      <th>thetas[43]</th>
      <td>0.241</td>
      <td>0.078</td>
      <td>0.139</td>
      <td>0.364</td>
      <td>0.039</td>
      <td>0.030</td>
      <td>5.0</td>
      <td>26.0</td>
      <td>3.16</td>
    </tr>
    <tr>
      <th>thetas[44]</th>
      <td>0.179</td>
      <td>0.068</td>
      <td>0.088</td>
      <td>0.292</td>
      <td>0.033</td>
      <td>0.025</td>
      <td>4.0</td>
      <td>15.0</td>
      <td>3.22</td>
    </tr>
    <tr>
      <th>thetas[45]</th>
      <td>0.178</td>
      <td>0.040</td>
      <td>0.124</td>
      <td>0.240</td>
      <td>0.018</td>
      <td>0.014</td>
      <td>5.0</td>
      <td>22.0</td>
      <td>2.23</td>
    </tr>
    <tr>
      <th>thetas[46]</th>
      <td>0.276</td>
      <td>0.060</td>
      <td>0.176</td>
      <td>0.345</td>
      <td>0.030</td>
      <td>0.023</td>
      <td>5.0</td>
      <td>23.0</td>
      <td>2.29</td>
    </tr>
    <tr>
      <th>thetas[47]</th>
      <td>0.234</td>
      <td>0.124</td>
      <td>0.147</td>
      <td>0.458</td>
      <td>0.062</td>
      <td>0.047</td>
      <td>5.0</td>
      <td>19.0</td>
      <td>2.62</td>
    </tr>
    <tr>
      <th>thetas[48]</th>
      <td>0.253</td>
      <td>0.075</td>
      <td>0.119</td>
      <td>0.372</td>
      <td>0.035</td>
      <td>0.027</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>2.41</td>
    </tr>
    <tr>
      <th>thetas[49]</th>
      <td>0.216</td>
      <td>0.085</td>
      <td>0.095</td>
      <td>0.350</td>
      <td>0.036</td>
      <td>0.027</td>
      <td>7.0</td>
      <td>25.0</td>
      <td>1.61</td>
    </tr>
    <tr>
      <th>thetas[50]</th>
      <td>0.250</td>
      <td>0.073</td>
      <td>0.139</td>
      <td>0.364</td>
      <td>0.035</td>
      <td>0.027</td>
      <td>5.0</td>
      <td>24.0</td>
      <td>2.81</td>
    </tr>
    <tr>
      <th>thetas[51]</th>
      <td>0.203</td>
      <td>0.033</td>
      <td>0.151</td>
      <td>0.251</td>
      <td>0.015</td>
      <td>0.012</td>
      <td>5.0</td>
      <td>17.0</td>
      <td>2.43</td>
    </tr>
    <tr>
      <th>thetas[52]</th>
      <td>0.342</td>
      <td>0.061</td>
      <td>0.235</td>
      <td>0.416</td>
      <td>0.030</td>
      <td>0.023</td>
      <td>5.0</td>
      <td>13.0</td>
      <td>2.79</td>
    </tr>
    <tr>
      <th>thetas[53]</th>
      <td>0.184</td>
      <td>0.101</td>
      <td>0.078</td>
      <td>0.379</td>
      <td>0.050</td>
      <td>0.038</td>
      <td>5.0</td>
      <td>13.0</td>
      <td>2.70</td>
    </tr>
    <tr>
      <th>thetas[54]</th>
      <td>0.225</td>
      <td>0.096</td>
      <td>0.127</td>
      <td>0.404</td>
      <td>0.046</td>
      <td>0.036</td>
      <td>6.0</td>
      <td>31.0</td>
      <td>1.73</td>
    </tr>
    <tr>
      <th>thetas[55]</th>
      <td>0.204</td>
      <td>0.070</td>
      <td>0.088</td>
      <td>0.324</td>
      <td>0.027</td>
      <td>0.020</td>
      <td>7.0</td>
      <td>20.0</td>
      <td>1.62</td>
    </tr>
    <tr>
      <th>thetas[56]</th>
      <td>0.267</td>
      <td>0.087</td>
      <td>0.123</td>
      <td>0.402</td>
      <td>0.042</td>
      <td>0.033</td>
      <td>4.0</td>
      <td>16.0</td>
      <td>3.60</td>
    </tr>
    <tr>
      <th>thetas[57]</th>
      <td>0.234</td>
      <td>0.045</td>
      <td>0.156</td>
      <td>0.330</td>
      <td>0.021</td>
      <td>0.016</td>
      <td>5.0</td>
      <td>15.0</td>
      <td>2.37</td>
    </tr>
    <tr>
      <th>thetas[58]</th>
      <td>0.233</td>
      <td>0.073</td>
      <td>0.106</td>
      <td>0.323</td>
      <td>0.036</td>
      <td>0.028</td>
      <td>5.0</td>
      <td>11.0</td>
      <td>3.16</td>
    </tr>
    <tr>
      <th>thetas[59]</th>
      <td>0.249</td>
      <td>0.068</td>
      <td>0.092</td>
      <td>0.340</td>
      <td>0.028</td>
      <td>0.021</td>
      <td>7.0</td>
      <td>28.0</td>
      <td>1.68</td>
    </tr>
    <tr>
      <th>thetas[60]</th>
      <td>0.275</td>
      <td>0.052</td>
      <td>0.192</td>
      <td>0.347</td>
      <td>0.025</td>
      <td>0.019</td>
      <td>5.0</td>
      <td>19.0</td>
      <td>2.54</td>
    </tr>
    <tr>
      <th>thetas[61]</th>
      <td>0.258</td>
      <td>0.034</td>
      <td>0.203</td>
      <td>0.316</td>
      <td>0.015</td>
      <td>0.011</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>2.16</td>
    </tr>
    <tr>
      <th>thetas[62]</th>
      <td>0.237</td>
      <td>0.068</td>
      <td>0.117</td>
      <td>0.302</td>
      <td>0.034</td>
      <td>0.026</td>
      <td>5.0</td>
      <td>35.0</td>
      <td>2.53</td>
    </tr>
    <tr>
      <th>thetas[63]</th>
      <td>0.246</td>
      <td>0.107</td>
      <td>0.076</td>
      <td>0.417</td>
      <td>0.050</td>
      <td>0.038</td>
      <td>5.0</td>
      <td>13.0</td>
      <td>2.37</td>
    </tr>
    <tr>
      <th>thetas[64]</th>
      <td>0.301</td>
      <td>0.104</td>
      <td>0.143</td>
      <td>0.460</td>
      <td>0.051</td>
      <td>0.039</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>3.10</td>
    </tr>
    <tr>
      <th>thetas[65]</th>
      <td>0.233</td>
      <td>0.052</td>
      <td>0.165</td>
      <td>0.332</td>
      <td>0.024</td>
      <td>0.019</td>
      <td>5.0</td>
      <td>29.0</td>
      <td>2.26</td>
    </tr>
    <tr>
      <th>thetas[66]</th>
      <td>0.309</td>
      <td>0.052</td>
      <td>0.229</td>
      <td>0.394</td>
      <td>0.025</td>
      <td>0.019</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>2.62</td>
    </tr>
    <tr>
      <th>thetas[67]</th>
      <td>0.292</td>
      <td>0.045</td>
      <td>0.225</td>
      <td>0.395</td>
      <td>0.019</td>
      <td>0.015</td>
      <td>6.0</td>
      <td>13.0</td>
      <td>1.79</td>
    </tr>
    <tr>
      <th>thetas[68]</th>
      <td>0.326</td>
      <td>0.053</td>
      <td>0.250</td>
      <td>0.416</td>
      <td>0.025</td>
      <td>0.019</td>
      <td>5.0</td>
      <td>14.0</td>
      <td>2.73</td>
    </tr>
    <tr>
      <th>thetas[69]</th>
      <td>0.417</td>
      <td>0.029</td>
      <td>0.386</td>
      <td>0.480</td>
      <td>0.014</td>
      <td>0.011</td>
      <td>5.0</td>
      <td>12.0</td>
      <td>2.24</td>
    </tr>
    <tr>
      <th>thetas[70]</th>
      <td>0.329</td>
      <td>0.073</td>
      <td>0.214</td>
      <td>0.439</td>
      <td>0.035</td>
      <td>0.026</td>
      <td>5.0</td>
      <td>20.0</td>
      <td>2.50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>r_hat</strong> is showing measure of each chain is converged to stationary distribution. <strong>r_hat</strong> should be less than or equal to 1.01, here we get r_hat far from 1.01 for each latent sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6fe366d15153f12426441b5626b7b379eef510d3ffa1835239a5fe5408cb323d.png" src="../_images/6fe366d15153f12426441b5626b7b379eef510d3ffa1835239a5fe5408cb323d.png" />
</div>
</div>
<p>Trace plots also looks terrible and does not seems to be converged! Also, black band shows that every sample is diverged from original distribution. So <strong>what’s wrong happeing here?</strong></p>
<p>Well, it’s related to support of latent variable. In HMC, the latent variable must be in an unconstrained space, but in above model <code class="docutils literal notranslate"><span class="pre">theta</span></code> is constrained in between 0 to 1. We can use change of variable trick to solve above problem</p>
</section>
<section id="change-of-variable">
<h2>Change of Variable<a class="headerlink" href="#change-of-variable" title="Permalink to this headline">#</a></h2>
<p>We can sample from logits which is in unconstrained space and in <code class="docutils literal notranslate"><span class="pre">joint_logprob()</span></code> we can convert logits to theta by suitable bijector (sigmoid). We calculate jacobian (first order derivaive) of bijector to tranform one probability distribution to another</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transform_fn</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span>
<span class="n">jacobian_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logit</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">transform_fn</span><span class="p">)(</span><span class="n">logit</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">joint_logprob_change_of_var</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>

    <span class="c1"># change of variable</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">transform_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">log_det_jacob</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">logit</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jacobian_fn</span><span class="p">(</span><span class="n">logit</span><span class="p">)))(</span><span class="n">logits</span><span class="p">))</span>

    <span class="c1"># improper prior for a,b</span>
    <span class="n">logprob_ab</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5</span><span class="p">))</span>

    <span class="c1"># logprob prior of theta</span>
    <span class="n">logprob_thetas</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># loglikelihood of y</span>
    <span class="n">logprob_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">probs</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">y</span><span class="p">))(</span>
            <span class="n">n_of_positives</span><span class="p">,</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">thetas</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">logprob_ab</span> <span class="o">+</span> <span class="n">logprob_thetas</span> <span class="o">+</span> <span class="n">logprob_y</span> <span class="o">+</span> <span class="n">log_det_jacob</span>
</pre></div>
</div>
</div>
</div>
<p>except change of variable in <code class="docutils literal notranslate"><span class="pre">joint_logprob()</span></code> function, everthing will remain same</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_params</span> <span class="o">=</span> <span class="n">n_rat_tumors</span> <span class="o">+</span> <span class="mi">2</span>


<span class="k">def</span> <span class="nf">init_param_fn</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    initialize a, b &amp; logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">key1</span><span class="p">,</span> <span class="n">key2</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">key1</span><span class="p">),</span>
        <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">key2</span><span class="p">),</span>
        <span class="s2">&quot;logits&quot;</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n_rat_tumors</span><span class="p">,</span> <span class="n">seed</span><span class="p">),</span>
    <span class="p">}</span>


<span class="n">init_param</span> <span class="o">=</span> <span class="n">init_param_fn</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
<span class="n">joint_logprob_change_of_var</span><span class="p">(</span><span class="n">init_param</span><span class="p">)</span>  <span class="c1"># sanity check</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DeviceArray(-1095.3221, dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">warmup</span> <span class="o">=</span> <span class="n">blackjax</span><span class="o">.</span><span class="n">window_adaptation</span><span class="p">(</span><span class="n">blackjax</span><span class="o">.</span><span class="n">nuts</span><span class="p">,</span> <span class="n">joint_logprob_change_of_var</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># we use 4 chains for sampling</span>
<span class="n">n_chains</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">keys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">n_chains</span><span class="p">)</span>
<span class="n">init_params</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">init_param_fn</span><span class="p">)(</span><span class="n">keys</span><span class="p">)</span>

<span class="n">initial_states</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">seed</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">warmup</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">param</span><span class="p">)[</span><span class="mi">0</span><span class="p">])(</span>
    <span class="n">keys</span><span class="p">,</span> <span class="n">init_params</span>
<span class="p">)</span>

<span class="c1"># can not vectorize kernel, since it is not jax.numpy array</span>
<span class="n">_</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">warmup</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">init_param_fn</span><span class="p">(</span><span class="n">rng_key</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 22.8 s, sys: 63.8 ms, total: 22.9 s
Wall time: 22.8 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">states</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">inference_loop_multiple_chains</span><span class="p">(</span>
    <span class="n">rng_key</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">initial_states</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_chains</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 11.9 s, sys: 71.9 ms, total: 12 s
Wall time: 12 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># convert logits samples to theta samples</span>
<span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="s2">&quot;thetas&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
<span class="k">del</span> <span class="n">states</span><span class="o">.</span><span class="n">position</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span>  <span class="c1"># delete logits</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make arviz trace from states</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">arviz_trace_from_states</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">infos</span><span class="p">,</span> <span class="n">burn_in</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">summ_df</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
<span class="n">summ_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>2.462</td>
      <td>0.989</td>
      <td>0.987</td>
      <td>4.076</td>
      <td>0.053</td>
      <td>0.045</td>
      <td>526.0</td>
      <td>505.0</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>b</th>
      <td>14.643</td>
      <td>5.836</td>
      <td>5.722</td>
      <td>24.597</td>
      <td>0.304</td>
      <td>0.257</td>
      <td>548.0</td>
      <td>530.0</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>thetas[0]</th>
      <td>0.064</td>
      <td>0.042</td>
      <td>0.001</td>
      <td>0.140</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2829.0</td>
      <td>1961.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[1]</th>
      <td>0.065</td>
      <td>0.042</td>
      <td>0.000</td>
      <td>0.139</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2342.0</td>
      <td>1973.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[2]</th>
      <td>0.063</td>
      <td>0.042</td>
      <td>0.002</td>
      <td>0.137</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2802.0</td>
      <td>2184.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[3]</th>
      <td>0.064</td>
      <td>0.043</td>
      <td>0.000</td>
      <td>0.139</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2377.0</td>
      <td>2013.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[4]</th>
      <td>0.064</td>
      <td>0.041</td>
      <td>0.002</td>
      <td>0.136</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2361.0</td>
      <td>2025.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[5]</th>
      <td>0.063</td>
      <td>0.041</td>
      <td>0.004</td>
      <td>0.140</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2575.0</td>
      <td>1866.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[6]</th>
      <td>0.063</td>
      <td>0.041</td>
      <td>0.001</td>
      <td>0.135</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>2407.0</td>
      <td>1668.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[7]</th>
      <td>0.065</td>
      <td>0.042</td>
      <td>0.001</td>
      <td>0.141</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2366.0</td>
      <td>1987.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[8]</th>
      <td>0.066</td>
      <td>0.044</td>
      <td>0.002</td>
      <td>0.144</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2977.0</td>
      <td>2341.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[9]</th>
      <td>0.065</td>
      <td>0.043</td>
      <td>0.000</td>
      <td>0.140</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2217.0</td>
      <td>1723.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[10]</th>
      <td>0.066</td>
      <td>0.043</td>
      <td>0.002</td>
      <td>0.143</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2915.0</td>
      <td>2347.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[11]</th>
      <td>0.068</td>
      <td>0.044</td>
      <td>0.001</td>
      <td>0.145</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2698.0</td>
      <td>1867.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[12]</th>
      <td>0.069</td>
      <td>0.045</td>
      <td>0.002</td>
      <td>0.149</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>3017.0</td>
      <td>1881.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[13]</th>
      <td>0.070</td>
      <td>0.046</td>
      <td>0.000</td>
      <td>0.150</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>2497.0</td>
      <td>1584.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[14]</th>
      <td>0.091</td>
      <td>0.048</td>
      <td>0.014</td>
      <td>0.182</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5065.0</td>
      <td>2184.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[15]</th>
      <td>0.092</td>
      <td>0.047</td>
      <td>0.013</td>
      <td>0.178</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>4865.0</td>
      <td>2084.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[16]</th>
      <td>0.090</td>
      <td>0.046</td>
      <td>0.013</td>
      <td>0.174</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>3971.0</td>
      <td>2094.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[17]</th>
      <td>0.092</td>
      <td>0.049</td>
      <td>0.009</td>
      <td>0.179</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5146.0</td>
      <td>2263.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[18]</th>
      <td>0.094</td>
      <td>0.049</td>
      <td>0.014</td>
      <td>0.183</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5509.0</td>
      <td>2360.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[19]</th>
      <td>0.095</td>
      <td>0.049</td>
      <td>0.013</td>
      <td>0.183</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>4226.0</td>
      <td>1708.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[20]</th>
      <td>0.097</td>
      <td>0.051</td>
      <td>0.015</td>
      <td>0.192</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5367.0</td>
      <td>2076.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[21]</th>
      <td>0.097</td>
      <td>0.051</td>
      <td>0.012</td>
      <td>0.189</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>4888.0</td>
      <td>2517.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[22]</th>
      <td>0.105</td>
      <td>0.049</td>
      <td>0.020</td>
      <td>0.192</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5404.0</td>
      <td>2072.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[23]</th>
      <td>0.107</td>
      <td>0.048</td>
      <td>0.027</td>
      <td>0.196</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5993.0</td>
      <td>2303.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[24]</th>
      <td>0.111</td>
      <td>0.049</td>
      <td>0.026</td>
      <td>0.201</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>5686.0</td>
      <td>2498.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[25]</th>
      <td>0.120</td>
      <td>0.053</td>
      <td>0.027</td>
      <td>0.216</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7176.0</td>
      <td>2558.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[26]</th>
      <td>0.119</td>
      <td>0.053</td>
      <td>0.029</td>
      <td>0.217</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5593.0</td>
      <td>2497.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[27]</th>
      <td>0.120</td>
      <td>0.054</td>
      <td>0.033</td>
      <td>0.226</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6758.0</td>
      <td>2603.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[28]</th>
      <td>0.119</td>
      <td>0.053</td>
      <td>0.022</td>
      <td>0.212</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5915.0</td>
      <td>2312.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[29]</th>
      <td>0.119</td>
      <td>0.055</td>
      <td>0.030</td>
      <td>0.219</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>8167.0</td>
      <td>1921.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[30]</th>
      <td>0.120</td>
      <td>0.054</td>
      <td>0.028</td>
      <td>0.221</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>7447.0</td>
      <td>2366.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[31]</th>
      <td>0.126</td>
      <td>0.063</td>
      <td>0.014</td>
      <td>0.235</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5361.0</td>
      <td>2436.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[32]</th>
      <td>0.113</td>
      <td>0.037</td>
      <td>0.045</td>
      <td>0.181</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7152.0</td>
      <td>2540.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[33]</th>
      <td>0.123</td>
      <td>0.053</td>
      <td>0.030</td>
      <td>0.219</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>7042.0</td>
      <td>2469.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[34]</th>
      <td>0.118</td>
      <td>0.041</td>
      <td>0.044</td>
      <td>0.193</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>6880.0</td>
      <td>2839.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[35]</th>
      <td>0.123</td>
      <td>0.050</td>
      <td>0.034</td>
      <td>0.215</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>6443.0</td>
      <td>2613.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[36]</th>
      <td>0.131</td>
      <td>0.056</td>
      <td>0.039</td>
      <td>0.237</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6880.0</td>
      <td>2492.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[37]</th>
      <td>0.143</td>
      <td>0.043</td>
      <td>0.063</td>
      <td>0.224</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>9065.0</td>
      <td>2456.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[38]</th>
      <td>0.148</td>
      <td>0.044</td>
      <td>0.070</td>
      <td>0.230</td>
      <td>0.000</td>
      <td>0.000</td>
      <td>7589.0</td>
      <td>2877.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[39]</th>
      <td>0.147</td>
      <td>0.059</td>
      <td>0.043</td>
      <td>0.259</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7504.0</td>
      <td>2012.0</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>thetas[40]</th>
      <td>0.148</td>
      <td>0.059</td>
      <td>0.042</td>
      <td>0.255</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6642.0</td>
      <td>2876.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[41]</th>
      <td>0.150</td>
      <td>0.066</td>
      <td>0.040</td>
      <td>0.274</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>8647.0</td>
      <td>2608.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[42]</th>
      <td>0.177</td>
      <td>0.047</td>
      <td>0.089</td>
      <td>0.262</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>6834.0</td>
      <td>2760.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[43]</th>
      <td>0.185</td>
      <td>0.046</td>
      <td>0.100</td>
      <td>0.271</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>8221.0</td>
      <td>2201.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[44]</th>
      <td>0.176</td>
      <td>0.064</td>
      <td>0.064</td>
      <td>0.297</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>8205.0</td>
      <td>2454.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[45]</th>
      <td>0.174</td>
      <td>0.063</td>
      <td>0.065</td>
      <td>0.297</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7163.0</td>
      <td>2569.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[46]</th>
      <td>0.175</td>
      <td>0.062</td>
      <td>0.065</td>
      <td>0.291</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>8019.0</td>
      <td>2842.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[47]</th>
      <td>0.175</td>
      <td>0.063</td>
      <td>0.062</td>
      <td>0.290</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>8888.0</td>
      <td>2764.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[48]</th>
      <td>0.175</td>
      <td>0.065</td>
      <td>0.064</td>
      <td>0.300</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5794.0</td>
      <td>2664.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[49]</th>
      <td>0.176</td>
      <td>0.063</td>
      <td>0.067</td>
      <td>0.295</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7197.0</td>
      <td>2719.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[50]</th>
      <td>0.175</td>
      <td>0.063</td>
      <td>0.066</td>
      <td>0.296</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7907.0</td>
      <td>2149.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[51]</th>
      <td>0.192</td>
      <td>0.049</td>
      <td>0.108</td>
      <td>0.291</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>7109.0</td>
      <td>2693.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[52]</th>
      <td>0.180</td>
      <td>0.064</td>
      <td>0.063</td>
      <td>0.294</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7721.0</td>
      <td>2728.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[53]</th>
      <td>0.180</td>
      <td>0.064</td>
      <td>0.069</td>
      <td>0.298</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7725.0</td>
      <td>2966.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[54]</th>
      <td>0.180</td>
      <td>0.066</td>
      <td>0.065</td>
      <td>0.301</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7448.0</td>
      <td>2665.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[55]</th>
      <td>0.192</td>
      <td>0.065</td>
      <td>0.074</td>
      <td>0.308</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7691.0</td>
      <td>2332.0</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>thetas[56]</th>
      <td>0.214</td>
      <td>0.052</td>
      <td>0.125</td>
      <td>0.312</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>6836.0</td>
      <td>3001.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[57]</th>
      <td>0.220</td>
      <td>0.052</td>
      <td>0.120</td>
      <td>0.312</td>
      <td>0.001</td>
      <td>0.000</td>
      <td>6995.0</td>
      <td>2821.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[58]</th>
      <td>0.203</td>
      <td>0.068</td>
      <td>0.085</td>
      <td>0.336</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7709.0</td>
      <td>2366.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[59]</th>
      <td>0.203</td>
      <td>0.068</td>
      <td>0.081</td>
      <td>0.329</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6447.0</td>
      <td>2429.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[60]</th>
      <td>0.212</td>
      <td>0.067</td>
      <td>0.088</td>
      <td>0.335</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6387.0</td>
      <td>2458.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[61]</th>
      <td>0.209</td>
      <td>0.069</td>
      <td>0.084</td>
      <td>0.333</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>7440.0</td>
      <td>2506.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[62]</th>
      <td>0.220</td>
      <td>0.068</td>
      <td>0.102</td>
      <td>0.347</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>6950.0</td>
      <td>2915.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[63]</th>
      <td>0.231</td>
      <td>0.073</td>
      <td>0.104</td>
      <td>0.371</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5787.0</td>
      <td>2506.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[64]</th>
      <td>0.230</td>
      <td>0.072</td>
      <td>0.103</td>
      <td>0.361</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5660.0</td>
      <td>2837.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[65]</th>
      <td>0.231</td>
      <td>0.070</td>
      <td>0.114</td>
      <td>0.371</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5129.0</td>
      <td>2907.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[66]</th>
      <td>0.268</td>
      <td>0.055</td>
      <td>0.168</td>
      <td>0.370</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>5994.0</td>
      <td>2561.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[67]</th>
      <td>0.278</td>
      <td>0.057</td>
      <td>0.173</td>
      <td>0.389</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>4698.0</td>
      <td>2548.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[68]</th>
      <td>0.274</td>
      <td>0.058</td>
      <td>0.174</td>
      <td>0.389</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>4463.0</td>
      <td>2567.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[69]</th>
      <td>0.282</td>
      <td>0.071</td>
      <td>0.159</td>
      <td>0.424</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>3706.0</td>
      <td>2447.0</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>thetas[70]</th>
      <td>0.211</td>
      <td>0.076</td>
      <td>0.081</td>
      <td>0.354</td>
      <td>0.001</td>
      <td>0.001</td>
      <td>8008.0</td>
      <td>2704.0</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c2effc7fe9c1208856b82bb4f3929393b562c5f84cfc15e21c4a7ba5e31d4bb7.png" src="../_images/c2effc7fe9c1208856b82bb4f3929393b562c5f84cfc15e21c4a7ba5e31d4bb7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of divergence: </span><span class="si">{</span><span class="n">infos</span><span class="o">.</span><span class="n">is_divergent</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of divergence: 0
</pre></div>
</div>
</div>
</div>
<p>We can see that <strong>r_hat</strong> is less than or equal to 1.01 for each latent variable, trace plots looks converged to stationary distribution, and only few samples are diverged.</p>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="SGMCMC.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">MNIST Digit Recognition With a 3-Layer Perceptron</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Pathfinder.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Pathfinder</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Blackjax developers<br/>
  
      &copy; Copyright 2022, The Blackjax developers.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>